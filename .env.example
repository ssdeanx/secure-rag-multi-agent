# OpenAI API Configuration
# Can also use gemini must set OPENAI_BASE_URL and OPENAI_MODEL, OPENAI_EMBEDDING_BASE_URL, and EMBEDDING_MODEL
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-5-mini

# SERP API Configuration
# Get your API key from https://serpapi.com/manage-api-key
# Used for web search, news, trends, shopping, academic research, and local business queries
SERPAPI_API_KEY=your_serpapi_key_here
# Alpha Vantage API Configuration
# Get your API key from https://www.alphavantage.co/support/#api-key
# Used for financial data, stock market, and economic indicators
ALPHA_VANTAGE_API_KEY='your_alpha_vantage_api_key_here'
# Finnhub API Configuration
# Get your API key from https://finnhub.io/
# Used for real-time stock, forex, and crypto market data
FINNHUB_API_KEY='your_finnhub_api_key_here'
# Polygon API Configuration
# Get your API key from https://polygon.io/
# Used for real-time and historical market data
POLYGON_API_KEY='your_polygon_api_key_here'
# Google Generative AI Configuration (Gemini)
GOOGLE_GENERATIVE_AI_API_KEY='your_google_generative_ai_api_key_here'
GOOGLE_MODEL='gemini-2.5-flash'
# Google API Key (for Voice Agent, e.g., Google Text-to-Speech)
GOOGLE_API_KEY='your_google_api_key_here'
# Gemini OAuth Cache Directory
GEMINI_OAUTH_CACHE='~/.gemini/oauth_creds.json'

# Anthropic API Configuration
ANTHROPIC_API_KEY='your_anthropic_api_key_here'

# OpenRouter Configuration
OPENROUTER_API_KEY='your_openrouter_api_key_here'

# Optional: Mastra Telemetry (set to true to disable warnings)
# MASTRA_TELEMETRY_DISABLED=true

# OpenAI Embedding Model (or swap in your own embedder)
# text-embedding-3-small (1536 dims) or text-embedding-3-large (3072 dims)
# Note: Gemini embedding-001 produces 768 dims, but system is configured for 3072
EMBEDDING_MODEL='gemini-embedding-001'
#OPENAI_EMBEDDING_BASE_URL

# Smithery Configuration (optional, for advanced mcp)
SMITHERY_API_KEY='your_smithery_api_key_here'
SMITHERY_PROFILE='your_smithery_profile_here'

# Demo JWT Secret (for RBAC demonstration only, NOT for user authentication)
# This is used by backend tools for access control testing
JWT_SECRET='dev-secret'
TENANT='acme'

# Database Configuration (Storage)
# For local development, use file-based database
DATABASE_URL='file:./deep-research.db'
# For remote LibSQL (Turso), use the connection URL and auth token
# DATABASE_URL="libsql://your-database.turso.io"
# DATABASE_AUTH_TOKEN="your-auth-token"
# Vector Database Configuration (separate from storage if needed)
VECTOR_DATABASE_URL="file:./vector-store.db"
# VECTOR_DATABASE_AUTH_TOKEN=""

# PgVector HNSW Index Configuration (for high-dimensional embeddings)
# HNSW index type supports dimensions > 2000 (IVFFlat is limited to 2000)
#PG_HNSW_M=16                      # HNSW connections per layer (default: 16, higher = better recall, more memory)
#PG_HNSW_EF_CONSTRUCTION=64        # HNSW build-time candidates (default: 64, higher = better quality, slower build)
#PG_EF=100                         # HNSW query-time candidates (default: 100, higher = better recall, slower queries)
#PG_MIN_SCORE=0.7                  # Minimum similarity score for vector search results

# Production Optimization:
# For faster HNSW index builds, increase PostgreSQL maintenance_work_mem
# Example: ALTER SYSTEM SET maintenance_work_mem = '8GB'; (adjust based on available RAM)

# Langfuse Configuration (optional, for monitoring and logging)
# Get your keys from https://langfuse.com
LANGFUSE_PUBLIC_KEY="your_langfuse_public_key_here"
LANGFUSE_SECRET_KEY="your_langfuse_secret_key_here"
LANGFUSE_BASE_URL="https://us.cloud.langfuse.com"
SERVICE_NAME="mastra"
NODE_ENV="development"

# Cedar-OS Configuration (for frontend connection to Mastra backend)
# Mastra backend URL - Cedar will connect directly to this
NEXT_PUBLIC_MASTRA_URL="http://localhost:4111"
MASTRA_URL="http://localhost:4111"

# Supabase Configuration (REQUIRED for user authentication)
# Get these from your Supabase project settings at https://supabase.com/dashboard
SUPABASE_URL="https://your-project.supabase.co"
SUPABASE_ANON_KEY="your_supabase_anon_key_here"

# For client-side Supabase (use same values as above)
NEXT_PUBLIC_SUPABASE_URL="https://your-project.supabase.co"
NEXT_PUBLIC_SUPABASE_ANON_KEY="your_supabase_anon_key_here"

# Supabase Database Connection (for PostgreSQL/PgVector storage)
# This is the direct database URL, different from SUPABASE_URL above
# Get from Supabase Dashboard > Project Settings > Database > Connection String (Session Pooler)
SUPABASE="postgresql://postgres.xxxxx:password@aws-0-us-east-1.pooler.supabase.com:5432/postgres"

# GitHub OAuth Configuration (for Supabase OAuth)
# Configure these in your Supabase dashboard: Authentication > Providers > GitHub
# Callback URL should be: https://your-project.supabase.co/auth/v1/callback
GITHUB_CLIENT_ID="your_github_client_id_here"
GITHUB_CLIENT_SECRET="your_github_client_secret_here"

# GitHub API Key (optional, for GitHub integrations beyond OAuth)
GITHUB_API_KEY="your_github_api_key_here"
COPILOT_TOKEN="${GITHUB_API_KEY}"
# Server-side Supabase Auth (for backend services)
# These credentials are used by the Mastra backend to authenticate with Supabase
# Create a user in Supabase and use those credentials here
USER_EMAIL='user@example.com'
USER_PASSWORD='your_super_secret_password_here'

# Application URL (for OAuth redirects)
NEXT_PUBLIC_APP_URL='http://localhost:3000'
# Neo4j Aura Configuration (for graph database storage)
# Get your credentials from https://neo4j.com/cloud/
# Mcp Neo4j Agent Memory Configuration
NEO4J_URI='neo4j+s://your-instance-id.databases.neo4j.io'
NEO4J_USERNAME='neo4j'
NEO4J_PASSWORD='your_password_here'
NEO4J_DATABASE='neo4j'


OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_EXPORTER_OTLP_HEADERS=x-api-key=your-api-key

# =============================================================================
# VECTOR DATABASE CONFIGURATIONS
# =============================================================================
# The system supports multiple vector databases for flexible deployment scenarios.
# Configure only the vector store(s) you plan to use.
# Each vector database requires its own set of environment variables.
# Additional vector databases can be added as needed.
# Note: The vector database configuration is not directly related to the vector storage
# configuration. The vector storage configuration is used to store the embeddings
# and perform vector search.
# Also this is mainly for advanced users who want to experiment with different vector databases.
# Also for production, so users can choose their preferred vector database. by entering the key/value pairs below.
# =============================================================================

# AstraDB Configuration (Enterprise-grade managed vector database)
# Get credentials from https://astra.datastax.com
ASTRA_DB_TOKEN='your_astra_db_token_here'
ASTRA_DB_ENDPOINT='https://your-region-your-db-id.apps.astra.datastax.com'
ASTRA_DB_KEYSPACE='default_keyspace'
ASTRA_EMBEDDING_DIMENSION='1536'

# ChromaDB Configuration (Open-source vector database)
# For Chroma Cloud: Get API key from https://www.trychroma.com/
# For local instance: Set CHROMA_URL to http://localhost:8000
CHROMA_API_KEY='your_chroma_api_key_here'
CHROMA_TENANT='your_chroma_tenant_here'
CHROMA_DATABASE='your_chroma_database_here'
CHROMA_URL='http://localhost:8000'
CHROMA_EMBEDDING_DIMENSION='1536'

# Cloudflare Vectorize Configuration (Serverless vector storage)
# Get credentials from https://dash.cloudflare.com/
CF_ACCOUNT_ID='your_cloudflare_account_id_here'
CF_API_TOKEN='your_cloudflare_api_token_here'
CF_EMBEDDING_DIMENSION='1536'
# Cloudflare D1 Storage (for memory persistence)
CLOUDFLARE_D1_DATABASE_ID='your_d1_database_id_here'
CLOUDFLARE_D1_TABLE_PREFIX='dev_'
CLOUDFLARE_D1_BASE_URL='https://api.cloudflare.com/client/v4'
# Cloudflare Memory Configuration
CLOUDFLARE_MEMORY_LAST_MESSAGES='500'
CLOUDFLARE_SEMANTIC_TOP_K='5'
CLOUDFLARE_SEMANTIC_RANGE_BEFORE='3'
CLOUDFLARE_SEMANTIC_RANGE_AFTER='2'
CLOUDFLARE_THREAD_GENERATE_TITLE='true'

# LanceDB Configuration (Local columnar vector database)
# High-performance embedded vector storage
LANCE_DB_PATH='/tmp/lance_db'
LANCE_TABLE_NAME='governed_rag'
LANCE_EMBEDDING_DIMENSION='1536'

# MongoDB Atlas Configuration (Document-based vector storage)
# Get connection string from MongoDB Atlas dashboard
MONGODB_URI='mongodb+srv://user:password@cluster.mongodb.net/'
MONGODB_DATABASE='mastra_db'
MONGODB_COLLECTION='governed_rag'
MONGODB_EMBEDDING_DIMENSION='1536'

# Pinecone Configuration (Managed vector database)
# Get credentials from https://app.pinecone.io/
PINECONE_API_KEY='your_pinecone_api_key_here'
PINECONE_ENVIRONMENT='us-east1-gcp'
PINECONE_PROJECT_ID='your_pinecone_project_id_here'
PINECONE_EMBEDDING_DIMENSION='1536'

# OpenSearch Configuration (Elasticsearch-compatible vector search)
# For AWS OpenSearch: Get endpoint from AWS console
# For self-hosted: Set to http://localhost:9200
OPENSEARCH_URL='https://your-opensearch-domain.region.es.amazonaws.com'
OPENSEARCH_EMBEDDING_DIMENSION='1536'

# Qdrant Configuration (High-performance vector database)
# For Qdrant Cloud: Get URL and API key from https://cloud.qdrant.io/
# For local instance: Set QDRANT_URL to http://localhost:6333
QDRANT_URL='https://your-qdrant-cluster.cloud.qdrant.io:6333'
QDRANT_API_KEY='your_qdrant_api_key_here'
QDRANT_EMBEDDING_DIMENSION='1536'

# S3Vectors Configuration (AWS S3-based vector storage)
# Uses Amazon S3 Vectors (Preview) for serverless vector storage
S3_VECTORS_BUCKET_NAME='governed-rag-vectors'
AWS_REGION='us-east-1'
S3_EMBEDDING_DIMENSION='1536'

# Couchbase Configuration (Multi-model database with vectors)
# Get credentials from Couchbase Capella or Server dashboard
COUCHBASE_CONNECTION_STRING='couchbases://your-cluster.cloud.couchbase.com'
COUCHBASE_USERNAME='your_couchbase_username_here'
COUCHBASE_PASSWORD='your_couchbase_password_here'
COUCHBASE_BUCKET='governed_rag'
COUCHBASE_SCOPE='_default'
COUCHBASE_COLLECTION='vectors'
COUCHBASE_EMBEDDING_DIMENSION='1536'

# UPSTASH Configuration
UPSTASH_REDIS_REST_URL='your_upstash_redis_rest_url_here'
UPSTASH_REDIS_REST_TOKEN='your_upstash_redis_rest_token_here'
UPSTASH_VECTOR_REST_URL='your_upstash_vector_rest_url_here'
UPSTASH_VECTOR_REST_TOKEN='your_upstash_vector_rest_token_here'